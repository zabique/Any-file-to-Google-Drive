{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Lip TenDeepfake eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zabique/Any-file-to-Google-Drive/blob/master/Wav2Lip_TenDeepfake_eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE22UQtQ9YYi"
      },
      "source": [
        "# **Welcome to Wav2Lip colab mod by Ten Deepfake**\n",
        "\n",
        "# **There is no need for colab pro to use it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf9El9kpMnvd"
      },
      "source": [
        "## Prevent random disconnects\n",
        "\n",
        "This cell runs JS code to automatic reconnect to runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no5CH80eM1gi",
        "cellView": "form"
      },
      "source": [
        "#@title Start\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cA_SNxHxT0P"
      },
      "source": [
        "## Check GPU ##\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4, P100 and V100\n",
        "*   Here you can check the model of GPU before using Wav2Lip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiJ1TJKNj_J",
        "cellView": "form"
      },
      "source": [
        "#@title Start\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XCqT2ITN-In"
      },
      "source": [
        "## Mount your Google drive\n",
        "\n",
        "1. Connect to your google drive to store Wave2lip model files.\n",
        "2. Ctrl+v auth key and hit ENTER\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "cellView": "form"
      },
      "source": [
        "#@title Start\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "cellView": "form"
      },
      "source": [
        "#@title Clone Wav2Lip github repo\n",
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "cellView": "form"
      },
      "source": [
        "#@title Copy wav2lip_gan.pth model\n",
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RO0-LWzar-u-"
      },
      "source": [
        "#@title Copy wav2lip.pth model\n",
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "cellView": "form"
      },
      "source": [
        "#@title Uninstall tensorflow Confirm with y [ enter ]\n",
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "cellView": "form"
      },
      "source": [
        "#@title Requirements.txt\n",
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "cellView": "form"
      },
      "source": [
        "#@title Download Face detection model\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjaWJFs8B38"
      },
      "source": [
        "# Quick guide\n",
        "1. Create video file and upload it to /sample_data/input_video.mp4 (max 720p)\n",
        "2. Create audio file and upload it to /sample_data/input_audio.wav\n",
        "3. Both files have to be same length and above file format\n",
        "4. Target face in the video file, must be in ALL videoframes (So no black frames etc)\n",
        "\n",
        "Once creation process is complete u will find result file in the menu to the left, click Files\n",
        "By default, rendered video will be in \"/content/Wav2Lip/results/result_voice.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "cellView": "form"
      },
      "source": [
        "#@title Create Wav2Lip video (using wav2lip_gan.pth) GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "WxbzXZvLliiA"
      },
      "source": [
        "#@title Play result video -  50% scaling\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kt-krsEbz5j",
        "cellView": "form"
      },
      "source": [
        "#@title Download Result.mp4 to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/Wav2Lip/results/result_voice.mp4') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-4PqQrDcphU4"
      },
      "source": [
        "#@title 1.Create Wav2Lip video (using wav2lip.pth) NON-GAN\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8",
        "cellView": "form"
      },
      "source": [
        "#@title 2.Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces.\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "cellView": "form"
      },
      "source": [
        "#@title 3.Use more padding to include the chin region (u can manually edit pads dimensions viewing and changing the code)\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}